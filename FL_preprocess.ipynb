{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from src.datafolders import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(a, min_a = None, max_a = None):\n",
    "\tif min_a is None: min_a, max_a = np.min(a, axis = 0), np.max(a, axis = 0)\n",
    "\treturn (a - min_a) / (max_a - min_a + 0.0001), min_a, max_a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset, idx):\n",
    "\tfolder = os.path.join(output_folder, dataset, f'partition_{idx}')\n",
    "\tos.makedirs(folder, exist_ok=True)\n",
    "\n",
    "\tdataset_folder = 'data/EPS'\n",
    "\tfile = os.path.join(dataset_folder, f'eps{idx}.csv')\n",
    "\tdf = pd.read_csv(file, header=0)\n",
    "\n",
    "\tlbl = df['ANOMALY']\n",
    "\tdf = df.drop(['ANOMALY'], axis=1)\n",
    "\n",
    "\tsplit = int(len(df) * 0.7) # 70% train, 30% test\n",
    "\n",
    "\tdf_train = df.iloc[:split]\n",
    "\tdf_test = df.iloc[split:]\n",
    "\tlbl = lbl.iloc[split:]\n",
    "\n",
    "\tprint(lbl.value_counts())\n",
    "\t# 0 - Normal, 1 - Anomaly\n",
    "\n",
    "\ttrain, min_a, max_a = normalize(df_train.values)\n",
    "\ttest, _, _ = normalize(df_test.values, min_a, max_a)\n",
    "\n",
    "\tlabels = np.zeros_like(test)\n",
    "   \n",
    "\t# Convert one column to 3 columns of anomaly labels to match the test shape\n",
    "\tfor i in range(len(lbl)):\n",
    "\t\tif lbl.iloc[i] == 1:\n",
    "\t\t\tlabels[i, :] = 1\n",
    "\t\telse:\n",
    "\t\t\tlabels[i, :] = 0\n",
    "\n",
    "\t# First COLUMN is the Speed, Second COLUMN is the Angle, Third COLUMN is the Torque\n",
    "\tprint(\"Train Shape: \" + str(train.shape), \"Test Shape: \" + str(test.shape), \"Labels Shape: \" + str(labels.shape))\n",
    "\n",
    "\tfor file in ['train', 'test', 'labels']:\n",
    "\t\tnp.save(os.path.join(folder, f'{file}'), eval(file)) # Save as NPY file for faster loading\n",
    "\n",
    "\treturn pd.DataFrame(train), pd.DataFrame(test), pd.DataFrame(labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    37655\n",
      "1      857\n",
      "Name: ANOMALY, dtype: int64\n",
      "Train Shape: (89861, 3) Test Shape: (38512, 3) Labels Shape: (38512, 3)\n",
      "0    32532\n",
      "1     1389\n",
      "Name: ANOMALY, dtype: int64\n",
      "Train Shape: (79148, 3) Test Shape: (33921, 3) Labels Shape: (33921, 3)\n",
      "0    36322\n",
      "1      973\n",
      "Name: ANOMALY, dtype: int64\n",
      "Train Shape: (87019, 3) Test Shape: (37295, 3) Labels Shape: (37295, 3)\n",
      "0    27492\n",
      "1     1428\n",
      "Name: ANOMALY, dtype: int64\n",
      "Train Shape: (67480, 3) Test Shape: (28920, 3) Labels Shape: (28920, 3)\n"
     ]
    }
   ],
   "source": [
    "train1, test1, labels1 = load_data('EPS', 1)\n",
    "train2, test2, labels2 = load_data('EPS', 2)\n",
    "train3, test3, labels3 = load_data('EPS', 3)\n",
    "train4, test4, labels4 = load_data('EPS', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate all the dataframes\n",
    "train = pd.concat([train1, train2, train3, train4])\n",
    "test = pd.concat([test1, test2, test3, test4])\n",
    "labels = pd.concat([labels1, labels2, labels3, labels4])\n",
    "\n",
    "# Save the dataframes\n",
    "np.save(os.path.join(output_folder, 'EPS', 'train'), train)\n",
    "np.save(os.path.join(output_folder, 'EPS', 'test'), test)\n",
    "np.save(os.path.join(output_folder, 'EPS', 'labels'), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((323508, 3), (138648, 3), (138648, 3))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('data/EPS/eps1.csv', header=0)\n",
    "\n",
    "df2 = pd.read_csv('data/EPS/eps2.csv', header=0)\n",
    "\n",
    "df3 = pd.read_csv('data/EPS/eps3.csv', header=0)\n",
    "\n",
    "df4 = pd.read_csv('data/EPS/eps4.csv', header=0)\n",
    "\n",
    "df = pd.concat([df1, df2, df3, df4])\n",
    "df.to_csv('data/EPS/eps.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
